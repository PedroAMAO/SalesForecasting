# ===============================================
# üìà Previs√£o com Decomposi√ß√£o + ARIMA (vers√£o enxuta e robusta)
# ===============================================
import os, warnings, re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import streamlit as st
import io
from itertools import product
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error
from sklearn.model_selection import train_test_split
from statsmodels.tsa.arima.model import ARIMA
import base64
from reportlab.lib.pagesizes import A4
from reportlab.lib.units import cm
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.lib import colors
#from xgboost import XGBRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.ensemble import HistGradientBoostingRegressor


@st.cache_data(show_spinner=False)
def carregar_e_preparar_base(arquivo_bytes: bytes, nome_arquivo: str):
    import io
    file_like = io.BytesIO(arquivo_bytes)

    base = safe_sheet_read(file_like)
    base = normalize_columns(base)

    # garante tipos
    base['ano'] = pd.to_numeric(base['ano'], errors='coerce').astype('Int64')
    base['mes'] = pd.to_numeric(base['mes'], errors='coerce').astype('Int64')
    base['realizado'] = pd.to_numeric(base['realizado'], errors='coerce')
    base['filial'] = base['filial'].astype(str).str.strip()
  

    # data mensal
    base["data"] = [
        to_month_start_date(a, m) for a, m in zip(base["ano"], base["mes"])
    ]
    base = base.dropna(subset=["data"]).sort_values("data")

    # total por data e linha "Total"
    df_total = base.groupby("data", as_index=False)["realizado"].sum()
    df_total["filial"] = "Total"
    df_total["ano"] = df_total["data"].dt.year
    df_total["mes"] = df_total["data"].dt.month

    df_com_total = pd.concat([base, df_total], ignore_index=True)

    soma_filiais = (
        df_com_total[df_com_total["filial"] != "Total"]
        .groupby("data")["realizado"]
        .transform("sum")
    )
    df_com_total["total_por_data"] = soma_filiais
    df_com_total["pct_filial"] = df_com_total["realizado"] / df_com_total["total_por_data"]

    return df_com_total

# ==========================================================
# CACHE dos modelos (cl√°ssico, ARIMA e ML)
# ==========================================================

@st.cache_data(show_spinner=False)
def treinar_modelo_classico_cached(df_filial, data_corte, tipo_tendencia):
    return treinar_modelo_classico(
        df_filial=df_filial,
        data_corte=data_corte,
        tipo_tendencia=tipo_tendencia
    )

@st.cache_data(show_spinner=False)
def treinar_arima_ruido_cached(df_treino, arima_order):
    return treinar_arima_ruido(
        df_treino=df_treino,
        arima_order=arima_order
    )

@st.cache_data(show_spinner=False)
def treinar_modelo_ml_cached(
        df_filial,
        df_prev_classico_full,
        df_prev_arima_completo,
        data_corte,
        lag_window
    ):
    return treinar_modelo_ml(
        df_filial=df_filial,
        df_prev_classico_full=df_prev_classico_full,
        df_prev_arima_completo=df_prev_arima_completo,
        data_corte=data_corte,
        lag_window=lag_window
    )

# ==========================================================
# CACHE das previs√µes (Cl√°ssico, ARIMA e ML)
# ==========================================================

#@st.cache_data(show_spinner=False)
def prever_classico_cached(df_filial, modelo_classico):
    return prever_full_classico(modelo_classico, df_filial)


#@st.cache_data(show_spinner=False)
def prever_arima_cached(modelo_classico, modelo_arima, df_filial):
    return prever_full_arima(modelo_classico, modelo_arima, df_filial)


#@st.cache_data(show_spinner=False)
def prever_ml_cached(modelo_ml_obj,
                     df_filial,
                     df_prev_classico_full,
                     df_prev_arima_completo,
                     data_corte,
                     meses_a_frente,
                     is_share):
    return prever_ml(
        modelo_ml_obj,
        df_filial,
        df_prev_classico_full,
        df_prev_arima_completo,
        data_corte,
        meses_a_frente,
        is_share=is_share
    )



# üîí Limita threads (evita travamentos em alguns ambientes)
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["OPENBLAS_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"
os.environ["VECLIB_MAXIMUM_THREADS"] = "1"
os.environ["NUMEXPR_NUM_THREADS"] = "1"

warnings.filterwarnings("ignore")
st.set_page_config(layout="wide")

# ===============================
# UI / CSS
# ===============================
st.markdown("""
    <style>
        .main { padding: 2rem 5rem; }
        .block-container { max-width: 100%; min-height: 90vh; }
        html, body { font-size: 18px; }
    </style>
""", unsafe_allow_html=True)
st.title("üìà Previs√£o com Decomposi√ß√£o Log + Tend√™ncia + Sazonalidade")

# ===============================
# Utils
# ===============================

def prever_full_classico(modelo_classico, df_filial):
    """Gera previs√£o cl√°ssica (tend + saz + IC) somente no √≥rico."""
    prevs = []
    for _, row in df_filial.iterrows():
        t_i = int(row["t"])
        m_i = int(row["mes_num"])
        y, ic_inf, ic_sup, _ = modelo_classico.prever_nivel_com_ic(t_i, m_i)
        prevs.append({
            "data": row["data"],
            "previsao": y,
            "ic_inf": ic_inf,
            "ic_sup": ic_sup,
        })
    return pd.DataFrame(prevs)

def prever_full_arima(modelo_classico, modelo_arima, df_filial):
    """Reconstr√≥i previs√£o ARIMA (A+B) somente no √≥rico observado."""
    serie_residuo = modelo_arima.modelo.fittedvalues  # s√≥ A
    n_ = len(df_filial)

    # Como ARIMA s√≥ tem previs√µes do per√≠odo A, usamos apenas fitted
    # e completamos com forecast at√© completar o √≥rico (B)
    passos_faltando = n_ - len(serie_residuo)

    if passos_faltando > 0:
        futuros_B = modelo_arima.modelo.forecast(steps=passos_faltando)
        ruido_total = pd.concat([serie_residuo, futuros_B])
    else:
        ruido_total = serie_residuo

    ruido_total = ruido_total.reset_index(drop=True)

    prevs = []
    for idx, row in df_filial.iterrows():
        t_i = int(row["t"])
        m_i = int(row["mes_num"])

        tend_saz_log = modelo_classico.prever_log(t_i, m_i)
        ruido_i = float(ruido_total.iloc[idx])

        yhat_log = tend_saz_log + ruido_i

        prevs.append({
            "data": row["data"],
            "previsao": np.exp(yhat_log) - 1.0,
            "yhat_log": yhat_log
        })

    return pd.DataFrame(prevs)


def rolling_ml(df_filial, tipo_tendencia, arima_order,
               lag_window=6, janela_minima=12):

    resultados = []
    datas = df_filial['data'].unique()

    for i in range(janela_minima, len(datas)-1):
        data_corte = datas[i]
        data_target = data_corte + pd.DateOffset(months=1)

        # Se n√£o existe realizado do m√™s seguinte ‚Üí pula
        if data_target not in df_filial['data'].values:
            continue

        # ============================
        # 1) Modelo cl√°ssico at√© o corte
        # ============================
        modelo_classico, df_treino, _ = treinar_modelo_classico_cached(
            df_filial, data_corte, tipo_tendencia
        )

        # previs√µes cl√°ssicas SOMENTE at√© o corte (√≥rico)
        df_prev_classico_ = prever_full_classico(modelo_classico, df_filial[df_filial['data'] <= data_corte])

        # ============================
        # 2) Modelo ARIMA at√© o corte
        # ============================
        modelo_arima = treinar_arima_ruido_cached(df_treino, arima_order)

        # previs√µes ARIMA SOMENTE at√© o corte (√≥rico)
        df_prev_arima_ = prever_full_arima(modelo_classico, modelo_arima, df_filial[df_filial['data'] <= data_corte])

        # ============================
        # 3) Montar df_base somente at√© o corte
        # ============================
        df_base = (
            df_filial[df_filial['data'] <= data_corte][['data','alvo','t','mes_num']]
            .merge(df_prev_classico_[['data','previsao']].rename(columns={'previsao':'prev_cl'}),
                   on='data', how='left')
            .merge(df_prev_arima_[['data','previsao']].rename(columns={'previsao':'prev_ar'}),
                   on='data', how='left')
            .sort_values("data")
            .reset_index(drop=True)
        )

        # ============================
        # 4) Construir features (lags at√© t)
        # ============================
        df_feat, feature_cols = build_lags(df_base, lag_window)

        # agora df_feat cont√©m SOMENTE √ìRICO at√© t
        df_train = df_feat.copy()

        # ============================
        # 5) Treinar ML sem vazamento
        # ============================
        

        modelo_ml = HistGradientBoostingRegressor(
            learning_rate=0.1,
            max_depth=3,
            max_iter=200,
            random_state=42
        )



        modelo_ml.fit(df_train[feature_cols], df_train['alvo'])

        # ============================
        # 6) Previs√£o ML para t+1 (APENAS 1 PASSO)
        # ============================
        # obter prev estrutural para t+1
        t_next  = int(df_filial.loc[df_filial['data']==data_target,'t'])
        mes_next = int(data_target.month)

        prev_cl_t = float(modelo_classico.prever_nivel_com_ic(t_next, mes_next)[0])

        ruido_next = modelo_arima.modelo.forecast(steps=1).iloc[0]
        prev_ar_t = float(np.exp(modelo_classico.prever_log(t_next, mes_next) + ruido_next) - 1.0)

        # estado inicial: √∫ltima linha do df_train
        estado = df_train.iloc[-1].copy()

        # previs√£o ML usando next_step_predict
        estado, y_ml_next = next_step_predict(
            estado,
            prev_cl_t,
            prev_ar_t,
            modelo_ml,
            feature_cols,
            lag_window
        )

        y_real = df_filial.loc[df_filial['data']==data_target,'alvo'].values[0]

        erro_abs = abs(y_real - y_ml_next)
        erro_pct = erro_abs / max(1e-6, y_real)

        resultados.append({
            "data_corte": data_corte,
            "data_prev":  data_target,
            "real":       y_real,
            "prev":       float(y_ml_next),
            "erro_abs":   erro_abs,
            "erro_pct":   erro_pct
        })

    return pd.DataFrame(resultados)

def rolling_arima(df_filial, tipo_tendencia, arima_order, janela_minima=12):
    resultados = []
    datas = df_filial['data'].unique()

    for i in range(janela_minima, len(datas)-1):
        data_corte = datas[i]
        data_target = data_corte + pd.DateOffset(months=1)

        if data_target not in df_filial['data'].values:
            continue

        # treina modelo cl√°ssico
        modelo_classico, df_treino, _ = treinar_modelo_classico_cached(
            df_filial, data_corte, tipo_tendencia
        )

        # treina ARIMA nos res√≠duos ‚Äî igual ao gr√°fico
        modelo_arima = treinar_arima_ruido_cached(df_treino, arima_order)

        # t/m√™s do m√™s seguinte
        t_next = int(df_filial.loc[df_filial['data'] == data_target, 't'].values[0])
        mes_next = int(data_target.month)

        # previs√£o estrutural (tend + saz) do pr√≥ximo m√™s
        yhat_log = modelo_classico.prever_log(t_next, mes_next)

        # previs√£o ARIMA h=1
        ruido_prev = modelo_arima.modelo.forecast(steps=1).iloc[0]

        y_pred = np.exp(yhat_log + ruido_prev) - 1.0
        y_real = df_filial.loc[df_filial['data'] == data_target, 'alvo'].values[0]

        erro_abs = abs(y_real - y_pred)
        erro_pct = erro_abs / max(1e-6, y_real)

        resultados.append({
            "data_corte": data_corte,
            "data_prev": data_target,
            "real": y_real,
            "prev": y_pred,
            "erro_abs": erro_abs,
            "erro_pct": erro_pct,
        })

    return pd.DataFrame(resultados)
def rolling_classico(df_filial, tipo_tendencia, janela_minima=12):
    resultados = []
    datas = df_filial['data'].unique()

    for i in range(janela_minima, len(datas)-1):
        data_corte = datas[i]
        data_target = data_corte + pd.DateOffset(months=1)

        # n√£o existe realizado ‚Üí pula
        if data_target not in df_filial['data'].values:
            continue

        # treina o modelo cl√°ssico exatamente como no gr√°fico
        modelo_classico, df_treino, _ = treinar_modelo_classico_cached(
            df_filial, data_corte, tipo_tendencia
        )

        t_next = int(df_filial.loc[df_filial['data'] == data_target, 't'].values[0])
        mes_next = int(data_target.month)

        y_pred, _, _, _ = modelo_classico.prever_nivel_com_ic(t_next, mes_next)
        y_real = df_filial.loc[df_filial['data'] == data_target, 'alvo'].values[0]

        erro_abs = abs(y_real - y_pred)
        erro_pct = erro_abs / max(1e-6, y_real)

        resultados.append({
            "data_corte": data_corte,
            "data_prev": data_target,
            "real": y_real,
            "prev": y_pred,
            "erro_abs": erro_abs,
            "erro_pct": erro_pct,
        })

    return pd.DataFrame(resultados)


def rolling_eval(df_filial, modelo, meses_a_frente=1, janela_minima=12):
    """
    Avalia um modelo prevendo 1 m√™s √† frente em v√°rios cortes.
    df_filial      -> DataFrame da filial (data, alvo)
    modelo         -> fun√ß√£o que recebe (df, data_corte) e devolve previs√£o do pr√≥ximo m√™s
    """
    resultados = []
    datas = df_filial['data'].unique()

    for i in range(janela_minima, len(datas) - meses_a_frente):
        data_corte = datas[i]

        # data do target (m√™s seguinte)
        data_target = data_corte + pd.DateOffset(months=meses_a_frente)

        # Se n√£o existe realizado do target, pula
        if data_target not in df_filial['data'].values:
            continue

        y_real = df_filial.loc[df_filial['data'] == data_target, 'alvo'].values[0]

        # chama o modelo (Cl√°ssico, ARIMA ou ML)
        try:
            y_pred = modelo(df_filial, data_corte)
        except:
            continue

        erro_abs = abs(y_real - y_pred)
        erro_pct = erro_abs / max(1e-6, y_real)

        resultados.append({
            "data_corte": data_corte,
            "data_prev": data_target,
            "real": y_real,
            "prev": y_pred,
            "erro_abs": erro_abs,
            "erro_pct": erro_pct,
        })

    return pd.DataFrame(resultados)



def gerar_pdf_completo(
    filial,
    m_class_total, m_arima_total, m_ml_total,
    m_class_pos, m_arima_pos, m_ml_pos,
    relatorio_llm,
    grafico_png
):
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4,
                            rightMargin=2*cm, leftMargin=2*cm,
                            topMargin=2*cm, bottomMargin=2*cm)

    styles = getSampleStyleSheet()
    story = []

    # =============================
    # T√çTULO
    # =============================
    story.append(Paragraph(f"<b>Relat√≥rio de Previs√£o ‚Äî Filial {filial}</b>", styles["Title"]))
    story.append(Spacer(1, 0.4*cm))

    # =============================
    # IMAGEM DO GR√ÅFICO
    # =============================
    img_buf = io.BytesIO(grafico_png)
    story.append(Image(img_buf, width=16*cm, height=7*cm))
    story.append(Spacer(1, 0.6*cm))

    # =============================
    # M√âTRICAS (Tabela)
    # =============================
    dados_tabela = [
        ["Modelo", "MAPE (%)", "R¬≤", "RMSE"],
        ["Cl√°ssico", f"{m_class_total['MAPE (%)']:.2f}", f"{m_class_total['R¬≤']:.3f}", f"{m_class_total['RMSE']:.2f}"],
        ["ARIMA",   f"{m_arima_total['MAPE (%)']:.2f}", f"{m_arima_total['R¬≤']:.3f}", f"{m_arima_total['RMSE']:.2f}"],
    ]

    if m_ml_total:
        dados_tabela.append(
            ["ML", f"{m_ml_total['MAPE (%)']:.2f}", f"{m_ml_total['R¬≤']:.3f}", f"{m_ml_total['RMSE']:.2f}"]
        )

    tabela = Table(dados_tabela)
    tabela.setStyle(TableStyle([
        ('BACKGROUND', (0,0), (-1,0), colors.lightgrey),
        ('GRID', (0,0), (-1,-1), 0.5, colors.black),
        ('FONTNAME', (0,0), (-1,-1), 'Helvetica'),
        ('ALIGN', (1,1), (-1,-1), 'CENTER')
    ]))
    story.append(tabela)
    story.append(Spacer(1, 0.8*cm))

    # =============================
    # RELAT√ìRIO DA LLM
    # =============================
    story.append(Paragraph("<b>Interpreta√ß√£o Autom√°tica (LLM)</b>", styles["Heading2"]))
    for par in relatorio_llm.split("\n"):
        if par.strip():
            story.append(Paragraph(par.strip(), styles["BodyText"]))
            story.append(Spacer(1, 0.25*cm))

    doc.build(story)
    pdf_value = buffer.getvalue()
    buffer.close()
    return pdf_value



def extract_context_text(context_file):
    import pandas as pd
    import io
    

    filename = context_file.name.lower()

    # TXT
    if filename.endswith(".txt"):
        return context_file.read().decode("utf-8")

    # PDF
    if filename.endswith(".pdf"):
        import fitz   # PyMuPDF
        doc = fitz.open(stream=context_file.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        return text

    
    # CSV
    if filename.endswith(".csv"):
        df = pd.read_csv(context_file)
        return df.to_string()

    # XLSX
    if filename.endswith(".xlsx"):
        xls = pd.ExcelFile(context_file)
        df = xls.parse(xls.sheet_names[0])
        return df.to_string()

    return ""


def calc_metrics(y_true, y_pred):
    # garante arrays 1D lisinhos
    y_true = np.array(y_true).ravel()
    y_pred = np.array(y_pred).ravel()

    mape = mean_absolute_percentage_error(y_true, y_pred) * 100.0
    r2   = r2_score(y_true, y_pred)

    # ‚ö†Ô∏è sklearn antigo N√ÉO aceita squared=False ‚Üí calculamos RMSE ‚Äúna m√£o‚Äù
    mse  = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)

    return {
        'MAPE (%)': mape,
        'R¬≤': r2,
        'RMSE': rmse
    }


def safe_sheet_read(file):
    """Tenta ler 'Planilha1'; se n√£o existir, pega a primeira aba."""
    try:
        xl = pd.ExcelFile(file)
        sheet = 'Planilha1' if 'Planilha1' in xl.sheet_names else xl.sheet_names[0]
        df = xl.parse(sheet)
    except Exception:
        # fallback direto
        df = pd.read_excel(file)
    return df

def normalize_columns(df):
    cols = {c: c.strip().lower() for c in df.columns}
    df = df.rename(columns=cols)
    # suporta 'm√™s' ou 'mes'
    if 'm√™s' in df.columns and 'mes' not in df.columns:
        df = df.rename(columns={'m√™s': 'mes'})
    # padroniza nomes esperados
    rename_map = {}
    if 'ano' not in df.columns:
        # tenta achar algo parecido
        for c in df.columns:
            if c.startswith('ano'):
                rename_map[c] = 'ano'
    if 'filial' not in df.columns:
        for c in df.columns:
            if 'filial' in c:
                rename_map[c] = 'filial'
    if 'realizado' not in df.columns:
        for c in df.columns:
            if 'realiz' in c:
                rename_map[c] = 'realizado'
    df = df.rename(columns=rename_map)
    missing = [c for c in ['ano','mes','filial','realizado'] if c not in df.columns]
    if missing:
        raise ValueError(f"Colunas faltando: {missing}. Esperado: ano, m√™s/mes, Filial, Realizado")
    return df

def to_month_start_date(ano, mes):
    try:
        ano = int(ano)
        mes = int(mes)
        return pd.to_datetime(f"{ano}-{mes:02d}-01")
    except Exception:
        return pd.NaT

def clip_predictions(df, is_share):
    df = df.copy()

    # clip da previs√£o
    df['previsao'] = np.clip(df['previsao'], 0.0, None)

    # se n√£o tiver IC, s√≥ devolve
    if 'ic_inf' not in df.columns or 'ic_sup' not in df.columns:
        return df

    # se tiver IC, clipa eles tamb√©m
    df['ic_inf'] = np.clip(df['ic_inf'], 0.0, None)
    df['ic_sup'] = np.clip(df['ic_sup'], 0.0, None)

    return df

def parse_arima_order(s):
    s = s.strip()
    m = re.match(r'^\s*\(?\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\)?\s*$', s)
    if not m:
        raise ValueError("Formato inv√°lido. Use p,d,q (ex: 1,0,0).")
    return tuple(map(int, m.groups()))

# ============================================================
# üéØ MODELO CL√ÅSSICO (Tend√™ncia + Sazonalidade M√©dia)
# ============================================================
class ClassicalTrendSeasonalModel:
    def __init__(self, tipo_tendencia, media_log, modelo_tend, saz_media, sigma_ruido):
        self.tipo_tendencia = tipo_tendencia
        self.media_log = media_log
        self.modelo_tend = modelo_tend  # pode ser None se "M√©dia"
        self.saz_media = saz_media      # Series indexada por m√™s
        self.sigma_ruido = sigma_ruido  # desvio do ru√≠do no log

    def prever_log(self, t_i, mes_num):
        """Retorna previs√£o em log (tend√™ncia + sazonalidade)."""
        # Tend√™ncia
        if self.tipo_tendencia == "M√©dia":
            tend_i = self.media_log
        else:
            if self.tipo_tendencia == "Quadr√°tica":
                x = np.array([[t_i, t_i**2]])
            else:
                x = np.array([[t_i]])
            tend_i = float(self.modelo_tend.predict(x)[0])

        # Sazonalidade
        saz_i = float(self.saz_media.get(mes_num, 0.0))
        return tend_i + saz_i

    def prever_nivel_com_ic(self, t_i, mes_num):
        """
        Retorna: previs√£o no n√≠vel, ic_inf, ic_sup, yhat_log.
        """
        yhat_log = self.prever_log(t_i, mes_num)
        y = np.exp(yhat_log) - 1.0
        ic_inf = np.exp(yhat_log - 2.57 * self.sigma_ruido) - 1.0
        ic_sup = np.exp(yhat_log + 2.57 * self.sigma_ruido) - 1.0
        return y, ic_inf, ic_sup, yhat_log


def treinar_modelo_classico(df_filial, data_corte, tipo_tendencia):
    """
    Treina o modelo cl√°ssico (tend√™ncia + sazonalidade) at√© a data de corte.
    Retorna:
        modelo_classico  -> objeto ClassicalTrendSeasonalModel
        df_treino        -> base at√© o corte (j√° com residuo/ruido)
        df_real          -> base completa (se quiser usar depois)
    """
    df_treino = df_filial[df_filial['data'] <= data_corte].copy()
    df_real = df_filial.copy()

    # log sempre positivo (protege zero)
    df_treino['log_venda'] = np.log(df_treino['alvo'] + 1.0)
    df_real['log_venda'] = np.log(df_real['alvo'] + 1.0)

    media_log = df_treino['log_venda'].mean()

    # ---------------------------
    # Tend√™ncia
    # ---------------------------
    modelo_tend = None
    if tipo_tendencia == "M√©dia":
        tendencia_train = np.full(len(df_treino), media_log)
    else:
        X_tr = pd.DataFrame({'t': df_treino['t'].values})
        if tipo_tendencia == "Quadr√°tica":
            X_tr['t2'] = X_tr['t']**2

        modelo_tend = LinearRegression().fit(X_tr, df_treino['log_venda'])
        tendencia_train = modelo_tend.predict(X_tr)

    # ---------------------------
    # Sazonalidade m√©dia
    # ---------------------------
    df_treino['residuo'] = df_treino['log_venda'] - tendencia_train

    if tipo_tendencia != "M√©dia":
        saz_media = df_treino.groupby(df_treino['data'].dt.month)['residuo'].mean()
    else:
        saz_media = pd.Series(0.0, index=range(1, 13))

    # ru√≠do (residuo - sazonalidade)
    df_treino['ruido'] = df_treino['residuo'] - df_treino['data'].dt.month.map(saz_media)
    sigma_ruido = float(df_treino['ruido'].std())
    if not np.isfinite(sigma_ruido) or sigma_ruido == 0:
        sigma_ruido = 1e-6

    modelo_classico = ClassicalTrendSeasonalModel(
        tipo_tendencia=tipo_tendencia,
        media_log=media_log,
        modelo_tend=modelo_tend,
        saz_media=saz_media,
        sigma_ruido=sigma_ruido
    )

    return modelo_classico, df_treino, df_real


# ============================================================
# üîß Helper ‚Äî Modelo ARIMA encapsulado para o ru√≠do
# ============================================================

class ArimaRuidoModel:
    """
    Wrap simples para manter o ARIMA ajustado nos res√≠duos.
    """
    def __init__(self, modelo, order, n_treino):
        self.modelo = modelo     # modelo ARIMA do statsmodels j√° ajustado
        self.order = order       # tupla (p,d,q)
        self.n_treino = n_treino # quantidade de pontos no treino (√∫til em rolling)


def treinar_arima_ruido(df_treino, arima_order):
    """
    Ajusta um ARIMA nos res√≠duos do modelo cl√°ssico.

    df_treino deve conter:
        data, ruido

    arima_order √© uma tupla (p,d,q)

    Retorna:
        ArimaRuidoModel
    """

    serie = df_treino.set_index("data")["ruido"].dropna()

    # Seguran√ßa m√≠nima: impede ARIMA imposs√≠vel
    if len(serie) < sum(arima_order) + 3:
        raise ValueError(
            f"Poucos pontos ({len(serie)}) para treinar ARIMA com ordem {arima_order}"
        )

    modelo = ARIMA(serie, order=arima_order).fit()

    return ArimaRuidoModel(
        modelo=modelo,
        order=arima_order,
        n_treino=len(serie)
    )


# ============================================================
# üîç Otimiza√ß√£o opcional do ARIMA via Rolling-Origin (cross-val)
# ============================================================



def otimizar_arima(df_treino,
                   grid_p=range(0,3),
                   grid_d=range(0,3),
                   grid_q=range(0,3),
                   metrica='mape',
                   min_janela=12):
    """
    Rolling-Origin Cross-Validation 100% honesta.
    Avalia previs√µes one-step-ahead da s√©rie de ru√≠do do df_treino.

    Retorna:
        melhor -> dict {p,d,q,erro}
        resultados -> lista de tentativas
    """

    serie = df_treino.set_index("data")["ruido"].dropna()
    resultados = []

    for p, d, q in product(grid_p, grid_d, grid_q):
        try:
            # precisa de pelo menos (p+d+q) + janela m√≠nima
            if len(serie) < max(p, d, q) + min_janela:
                continue

            erros = []

            # Rolling-origin
            for corte_idx in range(min_janela, len(serie) - 1):
                serie_treino = serie.iloc[:corte_idx]
                verdadeiro = serie.iloc[corte_idx + 1]

                modelo_tmp = ARIMA(serie_treino, order=(p, d, q)).fit()
                prev = modelo_tmp.forecast(steps=1).iloc[0]

                if metrica == 'rmse':
                    erro = (verdadeiro - prev) ** 2
                else:  # mape-like: erro absoluto
                    erro = abs(verdadeiro - prev)

                erros.append(erro)

            if erros:
                resultados.append({
                    'p': p,
                    'd': d,
                    'q': q,
                    'erro': float(np.mean(erros))
                })

        except Exception:
            continue

    if not resultados:
        raise ValueError("Nenhum ARIMA v√°lido encontrado na valida√ß√£o rolling-origin.")

    melhor = min(resultados, key=lambda x: x['erro'])
    return melhor, resultados

# ============================================================
#  MACHINE LEARNING
# ============================================================


# ============================================================
#  FUN√á√ÉO 1 ‚Äî Build Lags (√≥rico at√© o corte)
# ============================================================

def build_lags(df_base, lag_window=6):
    """
    df_base deve conter:
        data, alvo, prev_cl, prev_ar, t, mes_num
    lag_window: N¬∫ de lags (N)
    Retorna:
        df_feat  -> base com todas as features √≥ricas
        feature_cols -> lista das features para treinar o modelo ML
    """

    df = df_base.copy().sort_values("data").reset_index(drop=True)
    feature_cols = []

    # -------------------------
    # 1. Lags de Y, Cl√°ssico, ARIMA
    # -------------------------
    for k in range(1, lag_window+1):
        df[f"lag_y_{k}"]  = df["alvo"].shift(k)
        df[f"lag_cl_{k}"] = df["prev_cl"].shift(k)
        df[f"lag_ar_{k}"] = df["prev_ar"].shift(k)

        feature_cols += [f"lag_y_{k}", f"lag_cl_{k}", f"lag_ar_{k}"]

        # ---------- Erros ----------
        df[f"err_cl_{k}"] = df[f"lag_y_{k}"] - df[f"lag_cl_{k}"]
        df[f"err_ar_{k}"] = df[f"lag_y_{k}"] - df[f"lag_ar_{k}"]

        feature_cols += [f"err_cl_{k}", f"err_ar_{k}"]

    # -------------------------
    # 2. Deltas (varia√ß√µes dentro da janela)
    # -------------------------
    for k in range(1, lag_window):
        df[f"delta_y_{k}"] = df[f"lag_y_{k}"] - df[f"lag_y_{k+1}"]
        df[f"delta_cl_{k}"] = df[f"lag_cl_{k}"] - df[f"lag_cl_{k+1}"]
        df[f"delta_ar_{k}"] = df[f"lag_ar_{k}"] - df[f"lag_ar_{k+1}"]

        df[f"delta_err_cl_{k}"] = df[f"err_cl_{k}"] - df[f"err_cl_{k+1}"]
        df[f"delta_err_ar_{k}"] = df[f"err_ar_{k}"] - df[f"err_ar_{k+1}"]

        feature_cols += [
            f"delta_y_{k}", f"delta_cl_{k}", f"delta_ar_{k}",
            f"delta_err_cl_{k}", f"delta_err_ar_{k}"
        ]

    # -------------------------
    # 3. Features contempor√¢neas
    # -------------------------
    df["feat_prev_cl_t"] = df["prev_cl"]
    df["feat_prev_ar_t"] = df["prev_ar"]

    df["feat_t"] = df["t"]
    df["feat_mes_sin"] = np.sin(2 * np.pi * df["mes_num"] / 12)
    df["feat_mes_cos"] = np.cos(2 * np.pi * df["mes_num"] / 12)

    feature_cols += ["feat_prev_cl_t", "feat_prev_ar_t", "feat_t",
                     "feat_mes_sin", "feat_mes_cos"]

    # Remover linhas incompletas
    df_feat = df.dropna(subset=feature_cols + ["alvo"]).reset_index(drop=True)

    return df_feat, feature_cols


# ============================================================
# üî∂ FUN√á√ÉO 2 ‚Äî Next Step Predict (forecast recursivo sem vazamento)
# ============================================================

def next_step_predict(estado, prev_cl_t, prev_ar_t,
                      modelo_ml, feature_cols, lag_window):

    estado = estado.copy()

    # ----- Atualiza previs√µes estruturais do m√™s -----
    estado["feat_prev_cl_t"] = prev_cl_t
    estado["feat_prev_ar_t"] = prev_ar_t

    # ----- Previs√£o ML -----
    X_step = pd.DataFrame([estado[feature_cols]])
    y_ml_t = modelo_ml.predict(X_step)[0]

    # ----- Atualiza lags de Y -----
    for k in range(lag_window, 1, -1):
        estado[f"lag_y_{k}"] = estado[f"lag_y_{k-1}"]
    estado["lag_y_1"] = y_ml_t

    # ----- Atualiza lags cl√°ssico -----
    for k in range(lag_window, 1, -1):
        estado[f"lag_cl_{k}"] = estado[f"lag_cl_{k-1}"]
    estado["lag_cl_1"] = prev_cl_t

    # ----- Atualiza lags ARIMA -----
    for k in range(lag_window, 1, -1):
        estado[f"lag_ar_{k}"] = estado[f"lag_ar_{k-1}"]
    estado["lag_ar_1"] = prev_ar_t

    # ----- Calcula novos erros -----
    err_cl_t = y_ml_t - prev_cl_t
    err_ar_t = y_ml_t - prev_ar_t

    for k in range(lag_window, 1, -1):
        estado[f"err_cl_{k}"] = estado[f"err_cl_{k-1}"]
        estado[f"err_ar_{k}"] = estado[f"err_ar_{k-1}"]

    estado["err_cl_1"] = err_cl_t
    estado["err_ar_1"] = err_ar_t

    # ----- Atualiza deltas -----
    for k in range(1, lag_window):
        estado[f"delta_y_{k}"] = estado[f"lag_y_{k}"] - estado[f"lag_y_{k+1}"]
        estado[f"delta_cl_{k}"] = estado[f"lag_cl_{k}"] - estado[f"lag_cl_{k+1}"]
        estado[f"delta_ar_{k}"] = estado[f"lag_ar_{k}"] - estado[f"lag_ar_{k+1}"]

        estado[f"delta_err_cl_{k}"] = estado[f"err_cl_{k}"] - estado[f"err_cl_{k+1}"]
        estado[f"delta_err_ar_{k}"] = estado[f"err_ar_{k}"] - estado[f"err_ar_{k+1}"]

    # ----- Avan√ßa no tempo -----
    estado["t"] += 1
    estado["mes_num"] = (estado["mes_num"] % 12) + 1

    return estado, y_ml_t

def treinar_modelo_ml(df_filial, df_prev_classico_full, df_prev_arima_completo,
                      data_corte, lag_window=6):

    # monta df_base com prev_cl + prev_ar
    df_base = (
        df_filial[['data', 'alvo', 't', 'mes_num']]
        .merge(df_prev_classico_full[['data','previsao']].rename(columns={'previsao':'prev_cl'}),
               on='data', how='left')
        .merge(df_prev_arima_completo[['data','previsao']].rename(columns={'previsao':'prev_ar'}),
               on='data', how='left')
        .sort_values('data')
        .reset_index(drop=True)
    )

    # cria features
    df_feat, feature_cols = build_lags(df_base, lag_window)

    # corta para treino
    df_train = df_feat[df_feat['data'] <= data_corte]

    

    modelo_ml = HistGradientBoostingRegressor(
        learning_rate=0.05,
        max_depth=4,
        max_iter=300,
        random_state=42
    )


    modelo_ml.fit(df_train[feature_cols], df_train['alvo'])

    # ‚ö†Ô∏è PREVIS√ïES √ìRICAS DO ML ‚Äî ESSENCIAL PARA N√ÉO QUEBRAR NO PREVER!
    df_feat["prev_ml_"] = modelo_ml.predict(df_feat[feature_cols])

    # monta objeto
    return {
        "modelo": modelo_ml,
        "feature_cols": feature_cols,
        "lag_window": lag_window,
        "df_feat": df_feat,
        "df_base": df_base
    }


def prever_ml(modelo_ml_obj, df_filial, df_prev_classico_full, df_prev_arima_completo,
              data_corte, meses_a_frente, is_share=False):

    modelo_ml = modelo_ml_obj["modelo"]
    feature_cols = modelo_ml_obj["feature_cols"]
    lag_window = modelo_ml_obj["lag_window"]
    df_feat = modelo_ml_obj["df_feat"]

    # √≥rico at√© corte
    df_train = df_feat[df_feat['data'] <= data_corte]
    if df_train.empty:
        raise ValueError("N√£o h√° base √≥rica suficiente para ML at√© a data de corte!")

    estado = df_train.iloc[-1].copy()

    # Descobre quantos steps s√£o necess√°rios (√≥rico + futuro)
    ult_data_ = df_filial['data'].max()
    gap_meses = max(0, (ult_data_.year - data_corte.year)*12 +
                       (ult_data_.month - data_corte.month))
    total_steps = gap_meses + meses_a_frente

    futuros = []

    for i in range(1, total_steps+1):
        data_fut = data_corte + pd.DateOffset(months=i)

        # ------- Seguran√ßa obrigat√≥ria -------  
        # tenta buscar prev cl√°ssico e ARIMA ‚Äî se n√£o existir, pula
        row_cl = df_prev_classico_full.loc[df_prev_classico_full['data'] == data_fut]
        row_ar = df_prev_arima_completo.loc[df_prev_arima_completo['data'] == data_fut]

        if row_cl.empty or row_ar.empty:
            # Se a data ainda n√£o existe nas previs√µes cl√°ssica/ARIMA, n√£o d√° pra prever ML
            continue

        prev_cl_t = float(row_cl["previsao"].values[0])
        prev_ar_t = float(row_ar["previsao"].values[0])

        # ------- previs√£o recursiva -------  
        estado, y_ml_t = next_step_predict(
            estado,
            prev_cl_t,
            prev_ar_t,
            modelo_ml,
            feature_cols,
            lag_window
        )

        futuros.append({
            "data": data_fut,
            "previsao": float(y_ml_t)
        })

    # √≥rico j√° previsto pelo ML
    df_prev_ml_ = (
        df_feat[df_feat['data'] <= data_corte][["data", "prev_ml_"]]
        .rename(columns={"prev_ml_": "previsao"})
        .dropna(subset=["previsao"])
    )

    df_prev_ml_fut = pd.DataFrame(futuros)

    # Junta  + futuro
    df_prev_ml_full = pd.concat([df_prev_ml_, df_prev_ml_fut], ignore_index=True)

    # Ordena e limpa
    df_prev_ml_full = (
        df_prev_ml_full
        .dropna(subset=["data", "previsao"])
        .sort_values("data")
        .reset_index(drop=True)
    )

    # ICs triviais (ML ainda n√£o usa sigma)
    df_prev_ml_full["ic_inf"] = df_prev_ml_full["previsao"]
    df_prev_ml_full["ic_sup"] = df_prev_ml_full["previsao"]

    # Clip (para Share %)
    df_prev_ml_full = clip_predictions(df_prev_ml_full, is_share)

    return df_prev_ml_full


# ===============================
# Upload
# ===============================
arquivo = st.file_uploader("üì§ Fa√ßa upload do Excel de vendas", type=["xlsx"])

if not arquivo:
    st.markdown("""
    <div style='margin-top: 2rem; font-size: 18px;'>
      üîç <b>Instru√ß√µes:</b><br>
      ‚Ä¢ Envie um .xlsx com a aba <code>Planilha1</code> (ou usaremos a primeira).<br>
      ‚Ä¢ Colunas: <code>ano</code>, <code>m√™s</code>, <code>Filial</code>, <code>Realizado</code>.<br>
      ‚Ä¢ Depois, escolha filial e data de corte. üéØ
    </div>
    """, unsafe_allow_html=True)
    st.stop()

# ===============================
# Carregamento e preparo base
# ===============================
with st.spinner("Lendo e preparando os dados..."):
    df_com_total = carregar_e_preparar_base(
        arquivo_bytes=arquivo.getvalue(),
        nome_arquivo=arquivo.name
    )

# ===============================
# Sele√ß√µes
# ===============================
modelo_realizado = st.selectbox("üèÅ Base do realizado", ['Real R$', 'Real Share %'])

# Clip de previs√µes conforme o modo (R$ vs Share)
is_share = (modelo_realizado == 'Real Share %')
# filiais dispon√≠veis
if modelo_realizado == 'Real Share %':
    filiais_disponiveis = sorted(df_com_total[df_com_total['filial'] != 'Total']['filial'].unique())
else:
    filiais_disponiveis = sorted(df_com_total['filial'].unique())

filial = st.selectbox("üè¨ Selecione a filial", filiais_disponiveis)

df_filial = (
    df_com_total[df_com_total['filial'] == filial]
    .sort_values('data')
    .reset_index(drop=True)
)

if df_filial.empty:
    st.error("Sem dados para a filial selecionada.")
    st.stop()

# coluna alvo e log
if modelo_realizado == 'Real Share %':
    df_filial['alvo'] = df_filial['pct_filial'].fillna(0.0)
else:
    df_filial['alvo'] = df_filial['realizado'].fillna(0.0)

# eixo temporal e m√™s
df_filial['t'] = np.arange(len(df_filial))
df_filial['mes_num'] = df_filial['data'].dt.month

datas = df_filial['data'].tolist()
default_corte = datas[-4] if len(datas) >= 4 else datas[-1]
data_corte = st.select_slider("üìÖ Data de corte para previs√£o", options=datas, value=default_corte)

tipo_tendencia = st.selectbox("üìà Tipo de Tend√™ncia", [ "Linear", "Quadr√°tica","M√©dia"])


# ===============================
# Tend√™ncia + sazonalidade (ENCAPSULADO)
# ===============================
modelo_classico, df_treino, df_real = treinar_modelo_classico_cached(
    df_filial=df_filial,
    data_corte=data_corte,
    tipo_tendencia=tipo_tendencia
)

# pega sigma e sazonalidade se quiser usar em outros lugares (ARIMA, etc.)
sigma_ruido = modelo_classico.sigma_ruido
saz_media = modelo_classico.saz_media

# Previs√£o cl√°ssica (sem ARIMA) para todo √≥rico
df_prev_classico_ = prever_classico_cached(df_filial, modelo_classico)


# ===============================
# ARIMA nos res√≠duos (ENCAPSULADO)
# ===============================
st.markdown("---")
st.subheader("üîÆ Previs√£o de Vendas Futuras")

meses_a_frente = st.number_input("Meses √† frente", min_value=1, max_value=24, value=6)

usar_otimizacao = st.checkbox("üîç Otimizar par√¢metros do ARIMA automaticamente", value=False)

if usar_otimizacao:
    # rodamos o rolling-origin para escolher o melhor ARIMA
    melhor,  = otimizar_arima(
        df_treino=df_treino,
        metrica='mape'
    )
    p, d, q = melhor['p'], melhor['d'], melhor['q']
    st.success(f"Melhor ARIMA encontrado: ({p},{d},{q}) ‚Äî erro m√©dio = {melhor['erro']:.4f}")

else:
    ordem_arima_txt = st.text_input("Ordem do ARIMA (p,d,q)", "1,0,0")
    p, d, q = parse_arima_order(ordem_arima_txt)
    st.info(f"Usando ARIMA manual: ({p},{d},{q})")


# ---------------------------------------
# treinar modelo ARIMA encapsulado
# ---------------------------------------
modelo_arima = treinar_arima_ruido_cached(df_treino, (p, d, q))
# √≥rico ARIMA (A) via cache ‚Äî N√ÉO recalcular manualmente
df_prev_arima_ = prever_arima_cached(
    modelo_classico,
    modelo_arima,
    df_filial
)


# ---------------------------------------
# Reconstru√ß√£o dos res√≠duos (A + B + C)
# ---------------------------------------
serie_residuo = df_treino.set_index("data")["ruido"]

tam_A = modelo_arima.n_treino
tam_B = len(df_filial) - tam_A
tam_C = meses_a_frente

# res√≠duos fitted (A)
residuos_A = modelo_arima.modelo.fittedvalues

# res√≠duos futuros (B + C)
steps_forecast = tam_B + tam_C
residuos_BC = modelo_arima.modelo.forecast(steps=steps_forecast)

# junta tudo
residuos_todos = pd.concat([residuos_A, residuos_BC])

datas_todas = pd.date_range(
    start=df_filial['data'].iloc[0],
    periods=len(residuos_todos),
    freq='MS'
)

df_all = pd.DataFrame({
    'data': datas_todas,
    't': np.arange(len(residuos_todos)),
    'mes_num': datas_todas.month,
    'ruido_prev': residuos_todos.values
})


# ===============================
# Reconstruir previs√£o ARIMA completa (A + B + C)
# ===============================
prevs_arima_full = []
for _, row in df_all.iterrows():
    yhat_log = modelo_classico.prever_log(int(row['t']), int(row['mes_num'])) + row['ruido_prev']
    prevs_arima_full.append({
        'data': row['data'],
        'previsao': np.exp(yhat_log) - 1.0,
        'yhat_log': yhat_log
    })

df_prev_arima_completo = pd.DataFrame(prevs_arima_full)

# # ===============================
# # Sigma do ARIMA (somente per√≠odo A, sem vazamento)
# # ===============================

# # 1) Reconstruir tend√™ncia + sazonalidade no per√≠odo A
# df_A = df_treino.copy()

# df_A["tend_saz_log"] = [
#     modelo_classico.prever_log(int(row.t), int(row.data.month))
#     for _, row in df_A.iterrows()
# ]

# # 2) Adiciona o ru√≠do fitted (ARIMA) ‚Äî alinhado pelo √≠ndice
# df_A["ruido_fitted"] = residuos_A.values

# # 3) Reconstr√≥i o yhat no log
# df_A["yhat_log"] = df_A["tend_saz_log"] + df_A["ruido_fitted"]

# # 4) C√°lculo do erro no log somente na √°rea de treino
# df_A["erro_log"] = df_A["log_venda"] - df_A["yhat_log"]

# # 5) Sigma baseado somente no treino
# sigma_arima = float(df_A["erro_log"].std())
# if not np.isfinite(sigma_arima) or sigma_arima == 0:
#     sigma_arima = 1e-6

# ===============================
# Aplicar Intervalo de Confian√ßa no forecast completo (A + B + C)
# # ===============================
# df_prev_arima_completo["ic_inf"] = (
#     np.exp(df_prev_arima_completo["yhat_log"] - 2.57 * sigma_arima) - 1.0
# )

# df_prev_arima_completo["ic_sup"] = (
#     np.exp(df_prev_arima_completo["yhat_log"] + 2.57 * sigma_arima) - 1.0
# )


# Junta cl√°ssico (√≥rico) + futuro cl√°ssico sem ARIMA
# (futuro cl√°ssico reaproveita sigma_ruido e tend√™ncia+sazonal)
ult_data = df_filial['data'].max()
datas_fut = pd.date_range(start=ult_data + pd.DateOffset(months=1), periods=meses_a_frente, freq='MS')
fut = []
start_t = int(df_filial['t'].max()) + 1
for i, dta in enumerate(datas_fut):
    t_i = start_t + i
    m_i = int(dta.month)
    yhat_log = modelo_classico.prever_log(t_i, m_i)

    fut.append({
        'data': dta,
        'previsao': np.exp(yhat_log) - 1.0,
        'ic_inf': np.exp(yhat_log - 2.57*sigma_ruido) - 1.0,
        'ic_sup': np.exp(yhat_log + 2.57*sigma_ruido) - 1.0
    })
df_prev_futuro_classico = pd.DataFrame(fut)

df_prev_classico_full = pd.concat(
    [df_prev_classico_, df_prev_futuro_classico],
    ignore_index=True
)


df_prev_classico_full = clip_predictions(df_prev_classico_full, is_share)

df_prev_arima_completo = clip_predictions(df_prev_arima_completo, is_share)

# ============================================================
# üî∂ APLICA√á√ÉO MACHINE LEARNING
# ============================================================
# ============================================================
# üî∂ PIPELINE ML COMPLETO (treino + √≥rico + forecast futuro)
# ============================================================

# Ativa o modelo ML se o usu√°rio quiser
usar_ml = st.checkbox("ü§ñ Ativar previs√£o com Machine Learning (ML)", value=False)

if usar_ml:
    st.subheader("üîÆ Previs√£o via Modelo ML (Meta-Model)")
    lag_window = st.slider("Janela de lags (N)", min_value=3, max_value=12, value=6)

    # 1) Treina ML
    modelo_ml_obj = treinar_modelo_ml_cached(
        df_filial=df_filial,
        df_prev_classico_full=df_prev_classico_full,
        df_prev_arima_completo=df_prev_arima_completo,
        data_corte=data_corte,
        lag_window=lag_window
    )

    # 2) Faz toda previsao (√≥rico + futuro)
    df_prev_ml_full = prever_ml_cached(
            modelo_ml_obj,
            df_filial,
            df_prev_classico_full,
            df_prev_arima_completo,
            data_corte,
            meses_a_frente,
            is_share
        )

    # 3) Clipa se share
    df_prev_ml_full = clip_predictions(df_prev_ml_full, is_share)

  
# ======================================================
# üé® GR√ÅFICO MASTER ‚Äî Realizado vs Cl√°ssico vs ARIMA vs ML
# ======================================================
# ======================================================
# üîç PASSO 1.4.2 ‚Äî Valida√ß√£o e limpeza dos DFs de previs√£o
# ======================================================

def limpar_prev(df, nome):
    df = df.copy()

    # 1) manter apenas colunas essenciais
    cols_ok = [c for c in df.columns if c in ['data', 'previsao', 'ic_inf', 'ic_sup', 'yhat_log']]
    df = df[cols_ok]

    # 2) remover NaNs de data ou previs√£o
    df = df.dropna(subset=['data', 'previsao'])

    # 3) remover duplicatas de meses
    if df['data'].duplicated().any():
        st.warning(f"‚ö†Ô∏è Aten√ß√£o: {nome} tinha datas duplicadas. Removendo duplicatas automaticamente.")
        df = df.drop_duplicates(subset=['data'], keep='last')

    # 4) ordenar s√©rie temporal
    df = df.sort_values('data').reset_index(drop=True)

    return df

df_prev_classico_full  = limpar_prev(df_prev_classico_full, "Cl√°ssico")
df_prev_arima_completo = limpar_prev(df_prev_arima_completo, "ARIMA")
if usar_ml:
    df_prev_ml_full = limpar_prev(df_prev_ml_full, "ML")




st.markdown("## üìä Comparativo de Modelos ‚Äî Filial " + filial)

fig, ax = plt.subplots(figsize=(16, 6))

# ------------------------------------------------------
# BASE REAL - sempre atr√°s
# ------------------------------------------------------
ax.bar(df_filial['data'], 
       df_filial['alvo'], 
       width=20, 
       color='gray', 
       alpha=0.35, 
       label='Realizado', 
       zorder=1)

# ------------------------------------------------------
# CL√ÅSSICO (linha + IC FUTURO apenas)
# ------------------------------------------------------
ax.plot(df_prev_classico_full['data'],
        df_prev_classico_full['previsao'],
        'o--', color='black', label='Cl√°ssico', zorder=4)

# mask_future = df_prev_classico_full['data'] >= data_corte
# ax.fill_between(df_prev_classico_full.loc[mask_future, 'data'],
#                 df_prev_classico_full.loc[mask_future, 'ic_inf'],
#                 df_prev_classico_full.loc[mask_future, 'ic_sup'],
#                 alpha=0.12, color='black', zorder=2)

# ------------------------------------------------------
# ARIMA (linha + IC FUTURO apenas)
# ------------------------------------------------------
ax.plot(df_prev_arima_completo['data'],
        df_prev_arima_completo['previsao'],
        'o-', color='royalblue', linewidth=2,
        label='ARIMA (Res√≠duos)', zorder=5)

# mask_future_arima = df_prev_arima_completo['data'] >= data_corte
# ax.fill_between(df_prev_arima_completo.loc[mask_future_arima, 'data'],
#                 df_prev_arima_completo.loc[mask_future_arima, 'ic_inf'],
#                 df_prev_arima_completo.loc[mask_future_arima, 'ic_sup'],
#                 alpha=0.18, color='royalblue', zorder=2)

# ------------------------------------------------------
# ML (linha apenas, sem banda)
# ------------------------------------------------------
if usar_ml:
    ax.plot(df_prev_ml_full['data'],
            df_prev_ml_full['previsao'],
            'o-', color='purple', linewidth=2,
            label='ML Meta-Model', zorder=6)

# ------------------------------------------------------
# CORTE
# ------------------------------------------------------
ax.axvline(data_corte, linestyle='--', color='red', linewidth=2,
           label='Data de Corte', zorder=10)

# ------------------------------------------------------
# üìå FORMATA√á√ÉO PRELIMINAR
# ------------------------------------------------------
ax.set_title(f"üìà Comparativo de Modelos ‚Äî Filial {filial}", fontsize=16)
ax.set_xlabel("Data")
ax.set_ylabel("Vendas" if not is_share else "Participa√ß√£o (%)")
ax.legend()

# =========================================================
# üîß AJUSTE AUTOM√ÅTICO DO EIXO Y (5% ABAIXO DO MENOR VALOR)
# =========================================================
valores_min = []

# previs√µes
valores_min.append(df_prev_classico_full['previsao'].min())
valores_min.append(df_prev_arima_completo['previsao'].min())

if usar_ml:
    valores_min.append(df_prev_ml_full['previsao'].min())

# √≥rico (alvo real)
valores_min.append(df_filial['alvo'].min())

# menor valor geral
vmin = min(valores_min)

# aplica o desconto de 40%
limite_inferior = vmin * 0.95
ax.set_ylim(bottom=limite_inferior)

# =========================================================
# SALVAR EM PNG (IMPORTANTE: *DEPOIS* DO AJUSTE DE EIXO)
# =========================================================
buf = io.BytesIO()
fig.savefig(buf, format="png", dpi=300, bbox_inches="tight")
buf.seek(0)

# renderiza no streamlit
st.pyplot(fig)

# ======================================================
# üìê PREPARA√á√ÉO DAS S√âRIES PARA M√âTRICAS
# ======================================================

# 1) Blindagem ‚Äî padroniza coluna alvo
if "valor" in df_filial.columns and "alvo" not in df_filial.columns:
    df_filial = df_filial.rename(columns={"valor": "alvo"})


def alinhar(df_filial, df_prev, nome):
    df = (
        df_filial[['data', 'alvo']]
        .merge(df_prev[['data','previsao']], on='data', how='inner')
        .dropna(subset=['alvo','previsao'])
        .rename(columns={'previsao': nome})
        .sort_values('data')
        .reset_index(drop=True)
    )

    return df


# 2) Montar dataframes alinhados (somente datas em comum)
df_classico_valid = alinhar(df_filial, df_prev_classico_full, 'prev_class')
df_arima_valid    = alinhar(df_filial, df_prev_arima_completo, 'prev_arima')
df_ml_valid       = alinhar(df_filial, df_prev_ml_full, 'prev_ml') if usar_ml else None




# # 3) M√°scaras de per√≠odo
# mask_obs = df_classico_valid['alvo'].notnull()
# mask_pos = df_classico_valid['data'] > data_corte

# ======================================================
# üìê FUN√á√ÉO AUXILIAR PARA M√âTRICAS
# ======================================================


def metricas(df, col_pred, data_corte):
    if df is None or df.empty:
        vazio = {'MAPE (%)': np.nan, 'R¬≤': np.nan, 'RMSE': np.nan}
        return vazio, vazio

    mask_total = df['alvo'].notnull() & df[col_pred].notnull()
    mask_pos   = mask_total & (df['data'] > data_corte)

    m_total = calc_metrics(
        df.loc[mask_total, 'alvo'],
        df.loc[mask_total, col_pred],
    )

    if mask_pos.any():
        m_pos = calc_metrics(
            df.loc[mask_pos, 'alvo'],
            df.loc[mask_pos, col_pred],
        )
    else:
        m_pos = {'MAPE (%)': np.nan, 'R¬≤': np.nan, 'RMSE': np.nan}

    return m_total, m_pos

# ======================================================
# üìê M√âTRICAS FINAIS
# ======================================================
m_class_total, m_class_pos = metricas(df_classico_valid, "prev_class", data_corte)
m_arima_total, m_arima_pos = metricas(df_arima_valid, "prev_arima", data_corte)

if usar_ml:
    m_ml_total, m_ml_pos = metricas(df_ml_valid, "prev_ml", data_corte)
else:
    m_ml_total, m_ml_pos = None, None


# ======================================================
# üñ•Ô∏è EXIBI√á√ÉO
# ======================================================
st.markdown("## üìê M√©tricas Comparativas dos Modelos")

# ----- TOTAL -----
st.markdown("### üü¢ Per√≠odo Completo")

c1, c2, c3 = st.columns(3)
c1.metric("Cl√°ssico ‚Äî MAPE (%)", f"{m_class_total['MAPE (%)']:.2f}")
c2.metric("Cl√°ssico ‚Äî R¬≤", f"{m_class_total['R¬≤']:.3f}")
c3.metric("Cl√°ssico ‚Äî RMSE", f"{m_class_total['RMSE']:,.2f}")

c1, c2, c3 = st.columns(3)
c1.metric("ARIMA ‚Äî MAPE (%)", f"{m_arima_total['MAPE (%)']:.2f}")
c2.metric("ARIMA ‚Äî R¬≤", f"{m_arima_total['R¬≤']:.3f}")
c3.metric("ARIMA ‚Äî RMSE", f"{m_arima_total['RMSE']:,.2f}")

if usar_ml:
    c1, c2, c3 = st.columns(3)
    c1.metric("ML ‚Äî MAPE (%)", f"{m_ml_total['MAPE (%)']:.2f}")
    c2.metric("ML ‚Äî R¬≤", f"{m_ml_total['R¬≤']:.3f}")
    c3.metric("ML ‚Äî RMSE", f"{m_ml_total['RMSE']:,.2f}")

# ----- P√ìS-CORTE -----
st.markdown("### üî¥ Ap√≥s o Corte")

c1, c2, c3 = st.columns(3)
c1.metric("Cl√°ssico ‚Äî MAPE (%)", f"{m_class_pos['MAPE (%)']:.2f}" if pd.notna(m_class_pos['MAPE (%)']) else "‚Äî")
c2.metric("Cl√°ssico ‚Äî R¬≤", f"{m_class_pos['R¬≤']:.3f}" if pd.notna(m_class_pos['R¬≤']) else "‚Äî")
c3.metric("Cl√°ssico ‚Äî RMSE", f"{m_class_pos['RMSE']:,.2f}" if pd.notna(m_class_pos['RMSE']) else "‚Äî")

c1, c2, c3 = st.columns(3)
c1.metric("ARIMA ‚Äî MAPE (%)", f"{m_arima_pos['MAPE (%)']:.2f}" if pd.notna(m_arima_pos['MAPE (%)']) else "‚Äî")
c2.metric("ARIMA ‚Äî R¬≤", f"{m_arima_pos['R¬≤']:.3f}" if pd.notna(m_arima_pos['R¬≤']) else "‚Äî")
c3.metric("ARIMA ‚Äî RMSE", f"{m_arima_pos['RMSE']:,.2f}" if pd.notna(m_arima_pos['RMSE']) else "‚Äî")

if usar_ml:
    c1, c2, c3 = st.columns(3)
    c1.metric("ML ‚Äî MAPE (%)", f"{m_ml_pos['MAPE (%)']:.2f}" if pd.notna(m_ml_pos['MAPE (%)']) else "‚Äî")
    c2.metric("ML ‚Äî R¬≤", f"{m_ml_pos['R¬≤']:.3f}" if pd.notna(m_ml_pos['R¬≤']) else "‚Äî")
    c3.metric("ML ‚Äî RMSE", f"{m_ml_pos['RMSE']:,.2f}" if pd.notna(m_ml_pos['RMSE']) else "‚Äî")


# # ===============================
# # Logs (debug)
# # ===============================
# with st.expander("üõ†Ô∏è Logs (debug)"):
#     st.write(f"Sigma cl√°ssico (ru√≠do): {sigma_ruido:.6f}")
#     st.write(f"Sigma ARIMA (erro_log): {sigma_arima:.6f}")
#     st.write(f"ARIMA final: ({p},{d},{q}) ‚Äî treino em {len(serie_residuo)} pontos")
#     st.write(f"Dados dispon√≠veis: {df_filial['data'].min().date()} ‚Üí {df_filial['data'].max().date()} | corte: {data_corte.date()}")



# ======================================================
# üîÅ ROLLING EVALUATION ‚Äî 3 MODELOS (re-treinado a cada corte)
# ======================================================
st.markdown("## üîÅ Avalia√ß√£o Rolling ‚Äî 1 passo √† frente (Realista)")

rodar_rolling = st.button("üìâ Rodar Avalia√ß√£o Rolling (Realista)")

if rodar_rolling:
    st.warning("Executando rolling realista... isso pode demorar...")

    # -----------------------
    # CL√ÅSSICO
    # -----------------------
    df_roll_class = rolling_classico(
        df_filial=df_filial,
        tipo_tendencia=tipo_tendencia,
        janela_minima=12
    )

    # -----------------------
    # ARIMA
    # -----------------------
    df_roll_arima = rolling_arima(
        df_filial=df_filial,
        tipo_tendencia=tipo_tendencia,
        arima_order=(p, d, q),
        janela_minima=12
    )

    # -----------------------
    # ML
    # -----------------------
    if usar_ml:
        df_roll_ml = rolling_ml(
            df_filial=df_filial,
            tipo_tendencia=tipo_tendencia,
            arima_order=(p, d, q),
            lag_window=lag_window,
            janela_minima=12
        )
    else:
        df_roll_ml = None

    # -----------------------
    # RESUMO M√âTRICAS
    # -----------------------
    st.subheader("üìä Resultado Rolling Realista (MAPE M√©dio)")

    resumo = []
    resumo.append({
        "Modelo": "Cl√°ssico",
        "MAPE (%)": df_roll_class["erro_pct"].mean()*100,
        "Erro Abs M√©dio": df_roll_class["erro_abs"].mean()
    })
    resumo.append({
        "Modelo": "ARIMA",
        "MAPE (%)": df_roll_arima["erro_pct"].mean()*100,
        "Erro Abs M√©dio": df_roll_arima["erro_abs"].mean()
    })

    if usar_ml:
        resumo.append({
            "Modelo": "ML",
            "MAPE (%)": df_roll_ml["erro_pct"].mean()*100,
            "Erro Abs M√©dio": df_roll_ml["erro_abs"].mean()
        })

    st.dataframe(pd.DataFrame(resumo))

    # -----------------------
    # DETALHES
    # -----------------------
    st.markdown("### üìò Rolling ‚Äî Cl√°ssico")
    st.dataframe(df_roll_class)

    st.markdown("### üìò Rolling ‚Äî ARIMA")
    st.dataframe(df_roll_arima)

    if usar_ml:
        st.markdown("### üìò Rolling ‚Äî ML")
        st.dataframe(df_roll_ml)


    fig2, ax2 = plt.subplots(figsize=(16,6))

    ax2.plot(df_roll_class["data_prev"], df_roll_class["erro_pct"]*100,
            '-o', label="Cl√°ssico", color='black')

    ax2.plot(df_roll_arima["data_prev"], df_roll_arima["erro_pct"]*100,
            '-o', label="ARIMA", color='royalblue')

    if usar_ml:
        ax2.plot(df_roll_ml["data_prev"], df_roll_ml["erro_pct"]*100,
                '-o', label="ML", color='purple')

    ax2.set_title("Erro (%) por Corte ‚Äî Rolling Evaluation")
    ax2.set_xlabel("Data prevista")
    ax2.set_ylabel("MAPE (%)")
    ax2.legend()

    st.pyplot(fig2)


# ===============================
# Usar melhor Modelo
# ===============================

usar_best_model = st.button("üèÜ Usar Melhor Modelo (Rolling + IC Din√¢mico)")

def rolling_ml_h(df_filial, tipo_tendencia, arima_order, lag_window, max_h, janela_minima=12):

    resultados = []
    datas = df_filial["data"].unique()

    for i in range(janela_minima, len(datas)-1):
        data_corte = datas[i]

        # (1) cl√°ssico at√© corte
        modelo_classico, df_treino, _ = treinar_modelo_classico_cached(
            df_filial, data_corte, tipo_tendencia
        )

        # (2) arima at√© corte
        modelo_arima = treinar_arima_ruido_cached(df_treino, arima_order)

        # (3) previs√µes √≥rico completo
        df_cl = prever_classico_cached(df_filial, modelo_classico)
        df_ar =  prever_arima_cached(modelo_classico, modelo_arima, df_filial)

        # (4) treina ML at√© corte
        modelo_ml_obj = treinar_modelo_ml_cached(
            df_filial, df_cl, df_ar,
            data_corte=data_corte,
            lag_window=lag_window
        )

        # (5) prever H meses
        df_fore = prever_ml_cached(
            modelo_ml_obj,
            df_filial,
            df_prev_classico_full,
            df_prev_arima_completo,
            data_corte,
            meses_a_frente,
            is_share
        )

        for h in range(1, max_h+1):
            data_target = data_corte + pd.DateOffset(months=h)

            if data_target not in df_fore['data'].values:
                continue

            y_pred = df_fore.loc[df_fore['data']==data_target,'previsao'].values[0]
            y_real = df_filial.loc[df_filial['data']==data_target,'alvo'].values[0]

            erro_pct = abs(y_real - y_pred) / max(1e-6, y_real)

            resultados.append({
                "h": h,
                "real": y_real,
                "prev": y_pred,
                "erro_pct": erro_pct
            })

    return pd.DataFrame(resultados)


def rolling_arima_h(df_filial, tipo_tendencia, arima_order, max_h, janela_minima=12):
    resultados = []
    datas = df_filial['data'].unique()

    for i in range(janela_minima, len(datas) - 1):
        data_corte = datas[i]

        modelo_classico, df_treino, _ = treinar_modelo_classico_cached(
            df_filial, data_corte, tipo_tendencia
        )
        modelo_arima = treinar_arima_ruido_cached(df_treino, arima_order)

        for h in range(1, max_h+1):
            data_target = data_corte + pd.DateOffset(months=h)
            if data_target not in df_filial['data'].values:
                continue

            t_target = int(df_filial.loc[df_filial['data']==data_target,'t'].values[0])
            mes_target = int(data_target.month)

            yhat_log = modelo_classico.prever_log(t_target, mes_target)
            ruido_h = modelo_arima.modelo.forecast(steps=h).iloc[-1]

            y_pred = np.exp(yhat_log + ruido_h) - 1
            y_real = df_filial.loc[df_filial['data']==data_target,'alvo'].values[0]

            erro_pct = abs(y_real - y_pred) / max(1e-6, y_real)

            resultados.append({
                "h": h,
                "real": y_real,
                "prev": y_pred,
                "erro_pct": erro_pct
            })

    return pd.DataFrame(resultados)

def resumo_horizonte(df_roll_h, z=1.64):
    if df_roll_h.empty:
        return None

    df = (
        df_roll_h.groupby("h")["erro_pct"]
        .agg(["mean","std"])
        .rename(columns={"mean":"mean_erro","std":"std_erro"})
        .reset_index()
    )
    df["e_bound"] = (df["mean_erro"] + z*df["std_erro"]).clip(lower=0.0)
    return df

def aplicar_ic_h(df_prev, resumo_h, data_corte):
    if resumo_h is None:
        return df_prev

    df = df_prev.copy()

    mask_future = (df["data"] > data_corte) & df["previsao"].notnull()
    if not mask_future.any():
        return df

    # horizonte h de cada ponto
    h_vals = (
        (df.loc[mask_future,"data"].dt.year - data_corte.year) * 12 +
        (df.loc[mask_future,"data"].dt.month - data_corte.month)
    ).astype(int)
    df.loc[mask_future,"h"] = h_vals

    # merge (pode causar buracos)
    df = df.merge(resumo_h[["h","e_bound"]], on="h", how="left")

    # preencher faltantes para manter banda cont√≠nua
    df["e_bound"] = df["e_bound"].fillna(method="ffill").fillna(method="bfill").fillna(0.0)

    # aplicar IC
    df.loc[mask_future, "ic_inf"] = df.loc[mask_future,"previsao"] * (1 - df.loc[mask_future,"e_bound"])
    df.loc[mask_future, "ic_sup"] = df.loc[mask_future,"previsao"] * (1 + df.loc[mask_future,"e_bound"])

    # remover negativos
    df["ic_inf"] = df["ic_inf"].clip(lower=0.0)
    df["ic_sup"] = df["ic_sup"].clip(lower=0.0)

    return df.drop(columns=["h","e_bound"])

if usar_best_model:

    modelos_ativos = []
    # cl√°ssico √© sempre ativo
    modelos_ativos.append(("Cl√°ssico", df_prev_classico_full))

    # arima sempre ativo
    modelos_ativos.append(("ARIMA", df_prev_arima_completo))

    # ML opcional
    if usar_ml:
        modelos_ativos.append(("ML", df_prev_ml_full))

    # roda ROLLING H para cada modelo
    resultados = {}
    for nome, _ in modelos_ativos:

        if nome == "Cl√°ssico":
            # TODO: construir vers√£o rolling_h cl√°ssico
            continue

        elif nome == "ARIMA":
            df_r = rolling_arima_h(
                df_filial,
                tipo_tendencia,
                (p,d,q),
                max_h=meses_a_frente
            )
            resultados[nome] = df_r

        elif nome == "ML":
            df_r = rolling_ml_h(
                df_filial,
                tipo_tendencia,
                (p, d, q),
                lag_window,
                max_h=meses_a_frente
            )
            resultados["ML"] = df_r

    # escolhe o campe√£o por menor erro m√©dio no horizonte 1
    ranking = {
        nome: df["erro_pct"].mean() if not df.empty else np.inf
        for nome, df in resultados.items()
    }
    melhor_nome = min(ranking, key=ranking.get)
    st.success(f"üèÜ Melhor modelo via Rolling: **{melhor_nome}**")

    # resumo por horizonte
    resumo_h = resumo_horizonte(resultados[melhor_nome], z=1.64)

    # pega forecast do campe√£o
    if melhor_nome == "ARIMA":
        df_melhor_prev = df_prev_arima_completo.copy()
    elif melhor_nome == "ML":
        df_melhor_prev = df_prev_ml_full.copy()
    else:
        df_melhor_prev = df_prev_classico_full.copy()

    # aplica IC especial
    df_melhor_prev_ic = aplicar_ic_h(df_melhor_prev, resumo_h, data_corte)

if usar_best_model:

    # ... seu c√≥digo de rolling H, resumo, aplica√ß√£o IC etc

    # ---------------------------
    # üé® GR√ÅFICO VIP DO CAMPE√ÉO
    # ---------------------------
    st.markdown("## üèÜ Previs√£o com Intervalo de Confian√ßa Din√¢mico (Melhor Modelo)")

    fig_best, ax_best = plt.subplots(figsize=(16,6))

    ax_best.bar(df_filial['data'], df_filial['alvo'], width=20, alpha=0.3, color='gray')

    ax_best.plot(df_melhor_prev_ic['data'], df_melhor_prev_ic['previsao'],
                 '-o', color='green', label=f"{melhor_nome}")

    mask_fut = (
        (df_melhor_prev_ic['data'] > data_corte)
        & df_melhor_prev_ic['previsao'].notnull()
        & df_melhor_prev_ic['ic_inf'].notnull()
    )

    ax_best.fill_between(
        df_melhor_prev_ic.loc[mask_fut,'data'],
        df_melhor_prev_ic.loc[mask_fut,'ic_inf'],
        df_melhor_prev_ic.loc[mask_fut,'ic_sup'],
        alpha=0.25, color='green'
)


    ax_best.axvline(data_corte, linestyle='--', color='red')

    ax_best.set_title(f"IC din√¢mico por horizonte ‚Äî Modelo {melhor_nome}")
    ax_best.legend()

    st.pyplot(fig_best)







# ===============================
# Diagn√≥stico LLM ‚Äî Interpreta√ß√£o Autom√°tica
# ===============================
from openai import OpenAI

st.markdown("---")
st.header("üß© Interpreta√ß√£o Autom√°tica das Previs√µes")

context_file = st.file_uploader(
    "üìé Anexar arquivo de contexto (opcional)",
    type=["pdf"]
)

if st.button("üß† Gerar Interpreta√ß√£o com LLM"):

    with st.spinner("Analisando resultados e gerando interpreta√ß√£o..."):
        try:
            client = OpenAI(api_key=st.secrets["openai_api_key"])
            context_text = ""

            # ======================================================
            # üîß BLOCO OPCIONAL ‚Äî Rolling
            # ======================================================
            rolling_text = ""
            rolling_explicacao = """
A Avalia√ß√£o Rolling simula como cada modelo teria performado caso estiv√©ssemos,
oricamente, em ‚Äútempo real‚Äù. Ou seja: em cada m√™s t, o modelo √© treinado
usando apenas os dados dispon√≠veis at√© t, e faz uma previs√£o para t+1.

Esse procedimento evita absolutamente qualquer vazamento e mede:
‚Ä¢ estabilidade temporal do modelo,
‚Ä¢ robustez da tend√™ncia e da sazonalidade,
‚Ä¢ sensibilidade a mudan√ßas de regime,
‚Ä¢ consist√™ncia real do modelo ao longo da s√©rie.

√â um teste muito mais rigoroso e pr√≥ximo da vida real do que avaliar apenas o
per√≠odo p√≥s-corte atual.
"""

            # ======================================================
            # M√âTRICAS DO ROLLING (se existirem)
            # ======================================================
            if "df_roll_class" in locals():

                mape_class_roll = df_roll_class["erro_pct"].mean() * 100
                err_class_roll = df_roll_class["erro_abs"].mean()

                mape_arima_roll = df_roll_arima["erro_pct"].mean() * 100
                err_arima_roll = df_roll_arima["erro_abs"].mean()

                rolling_text += f"""
### üìâ Avalia√ß√£o Rolling (1 passo √† frente ‚Äî realista)

- **Modelo Cl√°ssico**
    ‚Ä¢ MAPE m√©dio rolling = {mape_class_roll:.2f}%  
    ‚Ä¢ Erro Absoluto M√©dio = {err_class_roll:.2f}

- **Modelo ARIMA**
    ‚Ä¢ MAPE m√©dio rolling = {mape_arima_roll:.2f}%  
    ‚Ä¢ Erro Absoluto M√©dio = {err_arima_roll:.2f}
"""

                if usar_ml and "df_roll_ml" in locals():
                    mape_ml_roll = df_roll_ml["erro_pct"].mean() * 100
                    err_ml_roll = df_roll_ml["erro_abs"].mean()

                    rolling_text += f"""
- **Modelo ML**
    ‚Ä¢ MAPE m√©dio rolling = {mape_ml_roll:.2f}%  
    ‚Ä¢ Erro Absoluto M√©dio = {err_ml_roll:.2f}
"""
            else:
                rolling_text = "Nenhuma avalia√ß√£o rolling foi executada."

            # ======================================================
            # BLOCO ML
            # ======================================================
            if usar_ml:
                bloco_ml = f"""
- Modelo de Machine Learning (XGBoost):
    ‚Ä¢ Lags utilizados: {lag_window}
    ‚Ä¢ MAPE = {m_ml_total['MAPE (%)']:.2f}%
    ‚Ä¢ R¬≤ = {m_ml_total['R¬≤']:.3f}
    ‚Ä¢ RMSE = {m_ml_total['RMSE']:.2f}
"""
            else:
                bloco_ml = ""

            # ======================================================
            # PROMPT
            # ======================================================
            prompt = f"""
Analise tecnicamente os resultados da previs√£o de vendas da filial "{filial}".

Use as m√©tricas abaixo:

- Modelo Cl√°ssico: MAPE = {m_class_total['MAPE (%)']:.2f}%, R¬≤ = {m_class_total['R¬≤']:.3f}, RMSE = {m_class_total['RMSE']:.2f}
- Modelo ARIMA:    MAPE = {m_arima_total['MAPE (%)']:.2f}%, R¬≤ = {m_arima_total['R¬≤']:.3f}, RMSE = {m_arima_total['RMSE']:.2f}
{bloco_ml}

### üß† O que analisar
Produza uma interpreta√ß√£o clara e objetiva abordando:
- Qual modelo performa melhor e por quais motivos;
- Comportamento p√≥s-corte: onde cada modelo acerta/erra;
- Confiabilidade dos intervalos de confian√ßa;
- Poss√≠veis causas para desvios (mudan√ßa de regime, sazonalidade at√≠pica, rupturas);
- Sugest√µes de melhoria (vari√°veis externas, sazonalidade din√¢mica, janela de lags, ML etc.).

### üåÄ Explica√ß√£o da Avalia√ß√£o Rolling
{rolling_explicacao}

### üìâ An√°lise Rolling (resultado realista)
{rolling_text}

Se houver arquivo de contexto, integre os fatos relevantes e gere insights pr√°ticos.
Mantenha tom consultivo, direto e t√©cnico.
"""

            # contexto
            if context_file:
                context_text = extract_context_text(context_file)

            prompt += context_text[:15000] + "\n---\n"

            # imagem
            img_base64 = base64.b64encode(buf.getvalue()).decode("utf-8")

            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "system",
                        "content": "Voc√™ √© um consultor s√™nior especializado em s√©ries temporais e gest√£o comercial."
                    },
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {"type": "image_url", "image_url": {
                                "url": f"data:image/png;base64,{img_base64}"
                            }}
                        ]
                    }
                ],
                temperature=0.4,
                max_tokens=900
            )

            relatorio = response.choices[0].message.content

            st.markdown("### üìä Interpreta√ß√£o Gerada:")
            st.markdown(relatorio)

            st.session_state['relatorio_llm'] = relatorio

        except Exception as e:
            st.error(f"Erro ao gerar interpreta√ß√£o: {e}")


# ===============================
# üìÑ PDF FINAL (sempre aparece depois de j√° existir relat√≥rio)
# ===============================
if 'relatorio_llm' in st.session_state:
    st.markdown("---")
    st.subheader("üìÑ Gerar PDF do Relat√≥rio Completo")

    if st.button("üì• Baixar PDF"):
        try:
            pdf_bytes = gerar_pdf_completo(
                filial,
                m_class_total, m_arima_total, m_ml_total,
                m_class_pos, m_arima_pos, m_ml_pos,
                st.session_state['relatorio_llm'],
                buf.getvalue()
            )

            st.download_button(
                label="‚¨áÔ∏è Clique aqui para baixar",
                data=pdf_bytes,
                file_name=f"relatorio_previsao_{filial}.pdf",
                mime="application/pdf"
            )
        except Exception as e:
            st.error(f"Erro ao gerar PDF: {e}")
























